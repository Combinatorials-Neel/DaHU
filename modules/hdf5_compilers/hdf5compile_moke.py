"""
Functions for MOKE parsing
"""
from ..functions.functions_moke import moke_integrate_pulse_array
from ..hdf5_compilers.hdf5compile_base import *
import io
import stringcase

def moke_info_from_filename(file_path):
    """
    Returns the scan number from the given filepath.

    The scan number is stored in the filename of the given filepath
    as 'pN_X_Y_magnetization.txt', where N is the scan number, X and Y are
    the wafer positions.

    Parameters
    ----------
    file_path : str
        The filepath to the MOKE data file (.txt)

    Returns
    -------
    dict
        A string containing the scan number.
    """
    if isinstance (file_path, str):
        file_path = Path(file_path)

    file_name = file_path.stem
    info_dict = {}

    pattern = r"p(\d+)_x(-?\d+(?:\.\d+)?)_y(-?\d+(?:\.\d+)?)"
    match = re.search(pattern, file_name)

    if match:
        info_dict['scan_number'] = float(match.group(1))
        info_dict['x_pos'] = float(match.group(2))
        info_dict['y_pos'] = float(match.group(3))
    else:
        raise Exception("Couldn't match pattern to moke filename")

    return info_dict

# def get_wafer_positions(filename):
#     """
#     Returns the wafer positions (x and y indices) from the given filepath.
#
#     The wafer positions are stored in the filename of the given filepath
#     as 'pN_XxYy_magnetization.txt', where N is the scan number, X and Y are
#     the wafer positions.
#
#     Parameters
#     ----------
#     filepath : str
#         The filepath to the MOKE data file (.txt)
#
#     Returns
#     -------
#     tuple
#         A tuple containing the x and y wafer positions.
#     """
#     pattern = r"p(\d+)_x(-?\d+(?:\.\d+)?)_y(-?\d+(?:\.\d+)?)"
#     match = re.search(pattern, filename)
#
#
#     return x_pos, y_pos


def read_header_from_moke(file_path):
    """
    Reads the header information from a MOKE data info file and returns it as a dictionary.

    Parameters
    ----------
    file_path : str or Path
        The filepath to the directory containing the MOKE data file and info.txt.

    Returns
    -------
    dict
        A dictionary containing the header information with keys like "Sample name", "Date", etc.
    """
    if isinstance (file_path, str):
        file_path = Path(file_path)

    header_dict = {}

    with open(file_path, 'r') as file:
        lines = file.readlines()

    header_dict["Dataset name"] = lines[0].strip().replace("#", "")
    header_dict["Date"] = lines[1].strip().replace("#", "")
    for line in lines[2:]:
        key, value = line.strip().split("=")
        header_dict[key] = value

    return header_dict


def read_data_from_moke(file_path_list):
    """
    Reads data from a MOKE data file and its associated pulse and sum data files.

    Parameters
    ----------
    filepath : str or Path
        The filepath to the MOKE data file.

    Returns
    -------
    tuple
        A tuple containing three lists: magnetization data, pulse data, and sum data. Each list contains the data of the corresponding file.
    """
    mag_data, pul_data, sum_data = [], [], []

    for file_path in file_path_list:
        file_path = str(file_path)
        if 'magnetization' in file_path:
            with open(file_path, 'r') as file:
                mag_file = file.readlines()
        elif 'pulse' in file_path:
            with open(file_path, 'r') as file:
                pul_file = file.readlines()
        elif 'sum' in file_path:
            with open(file_path, 'r') as file:
                sum_file = file.readlines()

    # Open the 3 datafiles at the same time and write everything in lists

    for mag, pul, sum in zip(mag_file[2:], pul_file[2:], sum_file[2:]):
        mag = mag.strip().split()
        pul = pul.strip().split()
        sum = sum.strip().split()

        mag_data.append([float(elm) for elm in mag])
        pul_data.append([float(elm) for elm in pul])
        sum_data.append([float(elm) for elm in sum])

    return mag_data, pul_data, sum_data


def get_time_from_moke(datasize):
    """
    Generates a list of time values based on the given data size.

    Parameters
    ----------
    datasize : int
        The number of time steps to generate.

    Returns
    -------
    list
        A list of time values in microseconds, each separated by a time step of 0.05 microseconds.
    """

    time_step = 0.05  # in microseconds (or 50ns)
    time = [j * time_step for j in range(datasize)]

    return time


def set_instrument_from_dict(moke_dict, node):
    """
    Writes the contents of the moke_dict dictionary to the HDF5 node.

    Args:
        moke_dict (dict): A dictionary containing the MOKE data and metadata, generated by the read_header_from_moke and read_data_from_moke functions.
        node (h5py.Group): The HDF5 group to write the data to.
    Returns:
        None
    """
    for key, value in moke_dict.items():
        if isinstance(value, dict):
            set_instrument_from_dict(value, node.create_group(key))
        else:
            # Use regex to split the unit from the data label
            pattern = r"^(.*?)\s*(?:\((.*?)\))?$"
            match = re.search(pattern, key)
            if match:
                name, unit = match.groups()
                name = stringcase.snakecase(name)
                node[name] = value
                node[name].attrs['unit'] = str(unit)
            else:
                node[key] = value

    return None

def write_moke_to_hdf5(hdf5_path, source_path, dataset_name = None, mode="a"):
    """
    Writes the contents of the MOKE data file (.txt) to the given HDF5 file.

    Args:
        HDF5_path (str or Path): The path to the HDF5 file to write the data to.
        measurement_dict (dict): Dictionary formatted as dict[filename] = file string.
        dataset_name (str): Name for the HDF5 group. If None, the name put into the moke will be used
        mode (str, optional): The mode to open the HDF5 file in. Defaults to "a".

    Returns:
        None
    """
    if isinstance (hdf5_path, str):
        hdf5_path = Path(hdf5_path)
    if isinstance(source_path, str):
        source_path = Path(source_path)

    if dataset_name is None:
        dataset_name = source_path.stem

    found_info = False
    header_dict =  {}
    for file_name in source_path.rglob('info.txt'):
        file_path = source_path / file_name
        header_dict = read_header_from_moke(file_path)
        found_info = True

    # Make sure that info.txt has been found
    if not found_info:
        raise Exception("Could not find info.txt file. Check measurement.")

    # Sort the dictionary by measurement "p_number" (index), and group measurements by indexes.
    # Example filename: p1_x-15.0_y45.0_magnetization.txt
    pattern = re.compile(r"p(\d+)")

    grouped_dict = defaultdict(list)

    for file_name in source_path.rglob('p*.txt'):
        match = re.search(pattern, str(file_name))
        if match:
            p_number = match.group(1)  # Extract p_number from measurement name
            file_path = source_path / file_name
            grouped_dict[p_number].append(file_path)  # Dictionary with measurements grouped by p_numbers

    with h5py.File(hdf5_path, mode) as hdf5_file:
        # Create the root group for the measurement
        moke_group = hdf5_file.create_group(f"{dataset_name}")
        moke_group.attrs["HT_type"] = "moke"

        # Create a scan_parameters group in moke with the contents of info.txt
        scan_parameters_group = moke_group.create_group("scan_parameters")
        set_instrument_from_dict(header_dict, scan_parameters_group)

        # For every position, write measurement to HDF5
        for scan_number in grouped_dict.keys():
            info_dict = moke_info_from_filename(grouped_dict[scan_number][0])
            mag_dict, pul_dict, sum_dict = read_data_from_moke(grouped_dict[scan_number])
            time_dict = get_time_from_moke(len(mag_dict))
            nb_acquisitions = len(mag_dict[0])

            x_pos = info_dict['x_pos']
            y_pos = info_dict['y_pos']

            scan = moke_group.create_group(f"({x_pos}, {y_pos})")

            # Instrument group for metadata
            instrument = scan.create_group("instrument")
            instrument.attrs["HT_class"] = "HTinstrument"
            instrument["x_pos"] = convertFloat(x_pos)
            instrument["y_pos"] = convertFloat(y_pos)
            instrument["x_pos"].attrs["units"] = "mm"
            instrument["y_pos"].attrs["units"] = "mm"

            # Measurement group for data
            data = scan.create_group("measurement")
            data.attrs["HT_class"] = "HTmeasurement"
            time = [convertFloat(t) for t in time_dict]
            time_node = data.create_dataset("time", data=time, dtype="float")
            time_node.attrs["units"] = "Î¼s"

            # Prepare arrays to generate mean
            integrated_pulse_arrays = []
            pulse_arrays = []
            mag_arrays = []
            sum_arrays = []

            # Create shot groups in HDF5
            for i in range(nb_acquisitions):
                shot_group = data.create_group(f"shot_{i+1}")
                mag = [convertFloat(t[i]) for t in mag_dict]
                mag_node = shot_group.create_dataset(
                    f"magnetization_{i+1}", data=mag, dtype="float"
                )
                mag_arrays.append(mag)

                pul = [convertFloat(t[i]) for t in pul_dict]
                pul_node = shot_group.create_dataset(
                    f"pulse_{i+1}", data=pul, dtype="float"
                )
                pulse_arrays.append(pul)

                integrated_pulse = moke_integrate_pulse_array(pul)
                integrated_pulse_node = shot_group.create_dataset(
                    f"integrated_pulse_{i+1}", data=integrated_pulse, dtype="float"
                )
                integrated_pulse_arrays.append(integrated_pulse)

                sum = [convertFloat(t[i]) for t in sum_dict]
                sum_node = shot_group.create_dataset(
                    f"reflectivity_{i+1}", data=sum, dtype="float"
                )
                sum_arrays.append(sum)

                mag_node.attrs["units"] = "V"
                pul_node.attrs["units"] = "V"
                sum_node.attrs["units"] = "V"

            # Add mean of measurements to HDF5
            mean_integrated_pulse = np.mean(np.stack(integrated_pulse_arrays), axis=0)
            mean_pulse = np.mean(np.stack(pulse_arrays), axis=0)
            mean_magnetization = np.mean(np.stack(mag_arrays), axis=0)
            mean_reflectivity = np.mean(np.stack(sum_arrays), axis=0)

            shot_group = data.create_group("shot_mean")
            shot_group.create_dataset(
                "integrated_pulse_mean", data=mean_integrated_pulse, dtype="float"
            )
            pulse_mean_node = shot_group.create_dataset(
                "pulse_mean", data=mean_pulse, dtype="float"
            )
            mag_mean_node = shot_group.create_dataset(
                "magnetization_mean", data=mean_magnetization, dtype="float"
            )
            sum_mean_node = shot_group.create_dataset(
                "reflectivity_mean", data=mean_reflectivity, dtype="float"
            )

            pulse_mean_node.attrs["units"] = "V"
            mag_mean_node.attrs["units"] = "V"
            sum_mean_node.attrs["units"] = "V"